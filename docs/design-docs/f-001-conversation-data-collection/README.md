# F-001: 会話データ収集機能

## 📋 機能概要

会話データ収集機能は、支援者と当事者の会話を音声からテキストに変換し、自然言語解析によって心理状態を分析する機能です。本機能はひきこもり支援における客観的な評価指標を提供し、データドリブンな支援最適化の基盤となります。

### 機能ID
**F-001**

### 優先度
**Must** - MVP対象機能

### 担当領域
会話データの収集・保存・分析・可視化

---

## 🎯 目的

### ビジネス目的
- 支援者の経験や勘に頼らない、科学的根拠に基づく支援の実現
- 自己開示が少ない当事者の心理状態を客観的に把握
- 支援効果の定量的な測定と可視化
- 支援継続率の向上（6ヶ月継続率70%以上を目標）

### 技術的目的
- 音声データの自動テキスト化による記録効率の向上
- 自然言語処理による感情・心理状態の自動分析
- 会話データの構造化と長期保存
- 後続の統合分析（F-003）への基盤データ提供

---

## 🏗️ システムアーキテクチャ

### コンポーネント構成

```
┌─────────────────────────────────────────────────────────┐
│                  ConversationModule                      │
│                  (統合UIコンポーネント)                   │
└────────────────────┬────────────────────────────────────┘
                     │
        ┌────────────┼────────────┐
        │            │            │
        ▼            ▼            ▼
┌──────────────┐ ┌──────────────┐ ┌──────────────┐
│ Conversation │ │ Conversation │ │ Conversation │
│ Recorder     │ │ History      │ │ Analysis     │
│              │ │              │ │              │
│ - 録音/停止  │ │ - 履歴一覧   │ │ - 統計グラフ │
│ - インポート │ │ - 詳細表示   │ │ - 感情分析   │
│ - 当事者選択 │ │ - 分析結果   │ │ - ストレス   │
│ - テキスト化 │ │              │ │              │
└──────┬───────┘ └──────┬───────┘ └──────┬───────┘
       │                │                │
       └────────────────┼────────────────┘
                        ▼
               ┌────────────────┐
               │ Mock Services  │
               │                │
               │ - SpeechToText │
               │ - NLP Analysis │
               │ - LocalStorage │
               └────────────────┘
```

### データフロー（現在のモック実装）

#### 録音フロー
```
┌──────────────┐
│ 音声録音開始  │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ 録音停止      │
└──────┬───────┘
       │
       ▼
┌──────────────────────┐
│ mockSpeechToText()   │ ← モックテキスト変換（2秒待機）
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ テキスト編集（任意）  │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ mockNLPAnalysis()    │ ← モック自然言語解析（1.5秒待機）
│ - 感情分析           │    - キーワードベース判定
│ - ストレスレベル     │    - ルールベース推論
│ - キーワード抽出     │
│ - 推奨アプローチ     │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ saveConversation()   │ ← LocalStorageに保存
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ 履歴・分析画面に反映  │
└──────────────────────┘
```

#### 🆕 インポートフロー（2025/10/17追加 / 2025/11/03更新）
```
┌──────────────────────┐
│ データをインポート    │
│ ボタンクリック        │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ ファイル選択          │
│ 音声: .mp3/.m4a      │
│ テキスト: .txt/.csv  │
└──────┬───────────────┘
       │
       ▼
┌──────────────────────┐
│ ファイル形式チェック  │ ← 対応形式以外はアラート表示
└──────┬───────────────┘
       │
       ├─────────────────┐
       │                 │
       ▼                 ▼
┌──────────────┐  ┌──────────────────┐
│テキストファイル│  │音声ファイル        │
│              │  │                  │
│FileReader    │  │mockSpeechToText()│ ← モックテキスト変換
│でUTF-8読み込み│  │(Phase 3: 実API)  │   （1.5秒待機）
└──────┬───────┘  └────────┬─────────┘
       │                   │
       └─────────┬─────────┘
                 │
                 ▼
┌──────────────────────┐
│ テキスト編集エリアに  │
│ 自動反映              │
└──────┬───────────────┘
       │
       ▼
   （以降、録音フローと同じ処理）
```

### 将来のデータフロー（Phase 2-3実装予定）

```
┌──────────────┐
│ 音声録音      │
└──────┬───────┘
       │
       ▼
┌────────────────────────────┐
│ Azure Speech Services API  │ ← リアルタイム文字起こし
│ - 音声 → テキスト変換       │   - 3秒以内のレスポンス目標
│ - 信頼度スコア              │   - 日本語特化モデル
└──────┬─────────────────────┘
       │
       ▼
┌────────────────────────────┐
│ OpenAI GPT-4 API           │ ← 高度な自然言語解析
│ - 感情分析（詳細）          │   - コンテキスト理解
│ - 心理状態推定              │   - 意図・文脈把握
│ - キーワード抽出            │   - ニュアンス検出
│ - 支援アプローチ提案        │
└──────┬─────────────────────┘
       │
       ▼
┌────────────────────────────┐
│ Database (Vercel Postgres) │ ← 永続化・構造化保存
│ - Conversation モデル       │   - 暗号化保存
│ - Patient 関連付け          │   - 監査ログ
│ - 分析結果の紐付け          │   - アクセス制御
└──────┬─────────────────────┘
       │
       ▼
┌────────────────────────────┐
│ 統合分析エンジン (F-003)    │ ← 会話×バイタル×支援事例
└────────────────────────────┘
```

---

## 🧩 機能詳細

### 1. 会話録音機能（ConversationRecorder）

**責務**:
- 支援セッション中の会話の録音
- **外部音声ファイル（mp3, m4a）またはテキストファイル（txt, csv）のインポート** 🆕 2025/10/17 / 更新 2025/11/03
- 当事者の選択と紐付け
- 録音時間の計測と表示
- 音声のテキスト変換

**UIコンポーネント**:
- 当事者選択ドロップダウン
- 録音開始/停止ボタン
- 録音時間タイマー表示
- **データをインポートボタン（音声ファイル、テキストファイル対応）** 🆕
- **インポート対応形式の表示** 🆕
- **インポートファイル名表示** 🆕
- テキスト編集エリア
- 保存して分析ボタン

**主要機能**:
```typescript
// 録音開始
handleStartRecording()
  - 録音状態を有効化
  - タイマー開始（1秒ごとカウント）
  - 録音中インジケーター表示

// 録音停止
handleStopRecording()
  - 録音状態を無効化
  - タイマー停止
  - 音声→テキスト変換開始（現在はモック）

// 🆕 データインポート（2025/10/17追加 / 2025/11/03更新）
handleImportButtonClick()
  - 隠しファイル入力をクリック
  - ファイル選択ダイアログを開く

handleFileImport(event)
  - 音声ファイル（mp3, m4a）またはテキストファイル（txt, csv）の読み込み
  - ファイル形式チェック（対応形式のみ）
  - テキストファイル：FileReader APIでUTF-8読み込み
  - 音声ファイル：音声→テキスト変換（現在はモック、Phase 3で実API統合）
  - テキスト編集エリアに自動反映

// 保存と分析
handleSaveConversation()
  - NLP分析実行（現在はモック）
  - ConversationRecordとして保存
  - 成功通知表示
  - フォームリセット
```

**インポート機能の詳細** 🆕:
- **対応形式**: 
  - 音声ファイル: mp3, m4a
  - テキストファイル: txt, csv (`accept=".mp3,.m4a,.txt,.csv,audio/mpeg,audio/mp4,audio/x-m4a,text/plain,text/csv"`)
- **処理フロー**:
  1. ユーザーが「データをインポート」ボタンをクリック
  2. ファイル選択ダイアログが開く
  3. 音声ファイル（mp3, m4a）またはテキストファイル（txt, csv）を選択
  4. ファイル形式チェック（対応形式以外はエラー）
  5. ファイル種別に応じた処理：
     - **テキストファイル**: FileReader APIで直接読み込み（UTF-8エンコーディング）
     - **音声ファイル**: 自動テキスト変換（現在はモック、1.5秒待機）
  6. テキスト編集エリアに結果を表示
  7. 既存の録音フローと同じく「保存して分析」で完了
- **将来の実装**（Phase 3）:
  - FileReader APIでArrayBuffer読み込み（音声ファイル）
  - Azure Speech Services APIに送信
  - リアルタイム音声認識結果の取得

### 2. 会話履歴機能（ConversationHistory）

**責務**:
- 過去の会話セッションの一覧表示
- 会話の詳細表示（モーダル）
- 分析結果の確認

**表示項目**:
- 当事者名
- 記録日時
- 感情状態（バッジ表示）
- ストレスレベル
- 会話内容（詳細ビュー）
- キーワード
- 推奨アプローチ

**データ取得**:
```typescript
// LocalStorageから履歴取得（現在）
getConversationHistory()
  - localStorage から JSON パース
  - ConversationRecord[] として返却

// 将来: データベースから取得
fetchConversationHistory(patientId, dateRange)
  - API経由でフィルタリング済みデータ取得
  - ページネーション対応
  - ソート・検索機能
```

### 3. 会話分析機能（ConversationAnalysis）

**責務**:
- **当事者選択機能**: ドロップダウンで当事者を選択（個別分析のみ）
- 感情分析の統計表示（円グラフ）
- ストレスレベルの分布（棒グラフ）
- 選択された当事者の会話数、平均ストレスレベル、主要な感情の表示

**主要機能**:
```typescript
✅ 当事者選択（Selectコンポーネント）
  - 個別選択: 特定の当事者のデータのみ分析
  - デフォルト: 最初の当事者を自動選択
  
✅ 動的フィルタリング
  - 選択された当事者の会話データでフィルタリング
  - リアルタイムでグラフ・統計を更新
  
✅ 会話データ件数の表示
  - 選択された当事者名と会話件数を明示
  
✅ Empty State対応
  - 会話データがない場合の表示
```

**可視化**:
- **感情分析円グラフ**: 選択された当事者の感情（ポジティブ、ニュートラル、ネガティブ、不安）の割合
- **ストレスレベル棒グラフ**: 選択された当事者のストレスレベル（低・中・高）の分布
- **サマリーカード**: 
  - 会話数（選択された当事者のセッション数）
  - 平均ストレスレベル（選択された当事者の平均）
  - 主要な感情（選択された当事者の最頻値）

**使用ライブラリ**:
- Recharts（PieChart, BarChart）
- Shadcn UI Card, Select コンポーネント

---

## 📊 データモデル

### ConversationAnalysis インターフェース

```typescript
interface ConversationAnalysis {
  emotion: string          // 感情状態（例: "ポジティブ", "不安"）
  stressLevel: string      // ストレスレベル（例: "低", "中", "高"）
  keywords: string[]       // 抽出されたキーワード
  recommendation: string   // 推奨される支援アプローチ
}
```

### ConversationRecord インターフェース

```typescript
interface ConversationRecord {
  id: string              // 一意識別子
  patientId: string       // 当事者ID
  patientName: string     // 当事者名（表示用）
  transcript: string      // テキスト化された会話内容
  analysis: ConversationAnalysis  // 分析結果
  timestamp: string       // 記録日時（ISO 8601形式）
}
```

### 将来のデータベーススキーマ（Phase 2実装予定）

```prisma
// Conversation モデル
model Conversation {
  id          String   @id @default(uuid())
  patientId   String
  patient     Patient  @relation(fields: [patientId], references: [id])
  
  // 会話データ
  transcript  String   @db.Text        // テキスト化された会話
  audioUrl    String?                  // 音声ファイルのURL（オプション）
  
  // 分析結果（JSON形式）
  sentiment   Json                     // 感情分析結果
  keywords    Json                     // キーワード抽出結果
  
  // メタデータ
  duration    Int?                     // 録音時間（秒）
  recordedAt  DateTime                 // 録音日時
  createdAt   DateTime @default(now()) // 作成日時
  updatedAt   DateTime @updatedAt      // 更新日時
  
  // 関連付け
  supporterId String?                  // 支援者ID（オプション）
  
  @@index([patientId, recordedAt])
}
```

---

## 🔧 技術スタック

### フロントエンド（実装済み）
- **React 19**: UIコンポーネント
- **Next.js 15 App Router**: ページルーティング
- **TypeScript**: 型安全性
- **Shadcn UI**: UIコンポーネントライブラリ
- **Tailwind CSS**: スタイリング
- **Recharts**: データ可視化（グラフ）

### バックエンド（Phase 2-3実装予定）
- **Vercel Postgres + Prisma ORM**: データベース
- **Azure Speech Services**: 音声→テキスト変換
- **OpenAI GPT-4**: 自然言語処理・感情分析
- **Next.js Server Actions**: API Layer
- **Firebase Auth**: 認証・認可

---

## 🔐 セキュリティ・プライバシー

### データ保護
- **会話内容の暗号化**: データベース保存時にAES-256で暗号化
- **個人情報の匿名化**: 統計データ化、個人紐づき情報は使用しない
- **アクセス制御**: RBAC（ロールベースアクセス制御）による権限管理
- **監査ログ**: すべての会話データアクセスを記録（3年間保持）

### HTTPS通信
- すべてのAPI通信はHTTPSで暗号化
- Azure Speech Services、OpenAI APIへの通信も暗号化

### プライバシー配慮
- 会話内容に含まれる個人情報の自動マスキング（将来実装）
- 当事者の同意取得プロセスの明確化
- データ保持期間の設定と自動削除

---

## 📁 ファイル構成

```
components/conversation/
├── conversation-module.tsx       # 統合モジュール（タブ切り替え）
├── conversation-recorder.tsx     # 録音・テキスト化機能
├── conversation-history.tsx      # 履歴表示機能
└── conversation-analysis.tsx     # 分析・統計表示機能

lib/
└── mock-conversation.ts          # モックサービス
    ├── mockSpeechToText()        # 音声→テキスト変換モック
    ├── mockNLPAnalysis()         # 自然言語解析モック
    ├── saveConversation()        # LocalStorage保存
    └── getConversationHistory()  # 履歴取得

app/dashboard/conversation/
└── page.tsx                      # ページコンポーネント
```

---

## 🎨 UI/UX設計

### デザイン原則
- **寄り添い型**: 安心感を与える、やさしいトーン
- **直感的操作**: 3クリック以内で主要機能にアクセス
- **視覚的フィードバック**: 録音中、処理中などの状態を明確に表示
- **レスポンシブ対応**: PC・タブレットで快適に利用可能

### カラーパレット
- **感情状態のカラーコード**:
  - ポジティブ: `bg-green-500`（緑）
  - ニュートラル: `bg-blue-500`（青）
  - ネガティブ: `bg-yellow-500`（黄）
  - 不安: `bg-orange-500`（オレンジ）

### アクセシビリティ
- Radix UIによるアクセシブルなUI基盤
- キーボードナビゲーション対応
- スクリーンリーダー対応（将来強化予定）

---

## 🔄 連携する機能

### 入力
- **支援者による録音操作**: 手動開始/停止
- **当事者の選択**: ドロップダウンから選択

### 出力
- **F-003: データ統合・分析機能**: 会話データを統合分析に提供
- **F-004: 支援者ダッシュボード**: 最近の会話データを表示
- **F-006: データ可視化機能**: グラフ・チャートで可視化

### 依存関係
- **F-005: ユーザー認証機能**: 支援者の認証・権限確認
- **データベース（Phase 2）**: 会話データの永続化
- **外部API（Phase 3）**: Azure Speech Services、OpenAI GPT-4

---

## 📈 今後の拡張計画

### Phase 2: データベース統合（2ヶ月以内開始）
- Vercel Postgres + Prisma ORM のセットアップ
- Conversationモデルの実装
- CRUD操作の実装
- LocalStorageからの移行

### Phase 3: 外部API連携
- Azure Speech Services統合
  - リアルタイム文字起こし
  - 日本語最適化
  - エラーハンドリング（オフライン時、API制限時）
- OpenAI GPT-4統合
  - 高度な感情分析
  - コンテキスト理解
  - プロンプトエンジニアリング

### Phase 4: 高度な分析機能
- 時系列分析（感情・ストレスの推移）
- 会話パターンの検出
- 支援効果の予測モデル
- 類似事例との比較分析

### 将来機能
- 音声ファイルの保存・再生
- 話者識別（支援者/当事者の自動分離）
- リアルタイムフィードバック（録音中の感情変化）
- 多言語対応（英語・中国語、5年目以降）

---

## 📚 参考資料

- [要件定義書 - F-001詳細仕様](/docs/requirements_specification.md#421-f-001-会話データ収集機能)
- [アーキテクチャドキュメント](/docs/overview.md)
- [実装状況ドキュメント](/docs/status.md)
- [Azure Speech Services ドキュメント](https://learn.microsoft.com/ja-jp/azure/cognitive-services/speech-service/)
- [OpenAI API リファレンス](https://platform.openai.com/docs/api-reference)

---

**最終更新**: 2025年11月3日（テキストファイルインポート機能追加）  
**ステータス**: Phase 1完了（UI実装）、Phase 2準備中  
**担当**: 開発チーム（2名体制）

